{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a1a6b1-c47b-4af2-844a-5f23d76ac3cb",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <th><h1>CS 3368</h1><h2>Introduction to Artificial Intelligence</h2>\n",
    "        <h1 style=\"color:maroon;\">Team Project Assignment</h1>\n",
    "        <h2 style=\"color:maroon;\">Third Submission</h2></th>\n",
    "        <th><img src=\"https://www.ttu.edu/traditions/images/raiderstatue.jpg\" width=225 height=116 /></th>\n",
    "        <th><p>Texas Tech University Matador Song</p>\n",
    "            <p>Fight, Matadors, for Tech!<br>\n",
    "                Songs of love we'll sing to thee,<br>\n",
    "                Bear our banners far and wide.<br>\n",
    "                Ever to be our pride,<br>\n",
    "                Fearless champions ever be.<br>\n",
    "                Stand on heights of victory.<br>\n",
    "                Strive for honor evermore.<br>\n",
    "                Long live the Matadors!</p>\n",
    "                <p>Music by Harry Lemaire, words by R.C. Marshall</p></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb7f8fb-882d-4098-adea-e82a20733aa5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color:darkgoldenrod\">Team 12: Blue2</h1>\n",
    "\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Harper Hill</bf></h4></li>\n",
    "<li style=\"color:maroon\"><h4><bf>Kharis Asifor-Paul</bf></h4></li>\n",
    "<li style=\"color:maroon\"><h4><bf>Zack Sims</bf></h4></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f507e5be-5fe6-415b-afa0-ed6e1f22f27c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color:darkgoldenrod\">AI Problem</h1>\n",
    "\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>What is the problem on which the team worked for this submission?</bf></h4></li>\n",
    "    <ul>\n",
    "        <li>Malicous Software infection computers</li>\n",
    "        <li>Lackluster malware detection in modern security software</li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Is it the same or a different problem than the problem(s) proposed in the proposal or the second submission?  If changes in scope or other changes to the problem have been made since the proposal or second submission, please explain here.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li>Same problem proposed in the proposal and our second submission</li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Please summarize here what advances and lessons learned the team made in solving the problem for this submission.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Advances:</h5>\n",
    "            <ul>\n",
    "                <li>The CNN model achieved a Test Accuracy of 93% when trained on the BODMAS feature vectors.</li>\n",
    "                <li>The data required for the decision tree has been filtered to remove unnecessary information.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><h5>Lessons Learned:</h5>\n",
    "            <ul>\n",
    "                <li>Benchmarking against journal papers helps identify weaknesses in preprocessing and training, and hybrid models combining CNNs and RNNs require careful integration but can potentially improve sequential data processing.</li>\n",
    "                <li>The quality and diversity of features in the BODMAS dataset significantly impact the accuracy and generalizability of the model.</li>\n",
    "                <li>The training/testing split for a dataset can affect the reported accuracy of a model.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939f91c-d08c-43f1-8290-9f6e0507e92a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color:darkgoldenrod\">What other ideas, models, approaches, and/or helpful suggestions have you found since the last team submission related to solving the AI problem or similar problems by others?</h1>\n",
    "\n",
    "<hr>\n",
    "<h2 style=\"color: teal\">From Journal/Conference Papers</h2>\n",
    "\n",
    "<p>Papers from previous submissions should not be listed here.</p>\n",
    "\n",
    "<p>Journal and conference papers report on research to solve problems.  They do not necessarily have tutorial instructions, but they do report on many ideas that were used in the past, the ideas used by the authors to solve the problem in the paper, and ideas for future research.  They can help you narrow down quickly promising ideas to use to solve a problem.  Examples of ideas are using A-star search and developing a modified version of A-star search to reduce the state space by sampling the actions.  Normal data processing, such as cleaning data, or normal steps to solve a problem would not be the ideas for which you are searching as you read the paper.</p>\n",
    "<p>Another thing that papers have are results that you can use to compare to your solution so you can see if your solution approach has merit.  If your solution does not do as well as solutions reported in the papers, use the papers to find ideas to improve the solution that you have.</p>\n",
    "<p>You want to look for papers listed in the Scopus database available through the <a href=\"https://ttu-primo.hosted.exlibrisgroup.com/primo-explore/dbsearch?vid=01TTU\">TTU Library's Website</a>, and enter \"Scopus\" into the search box.  Papers listed in Scopus will be in venues recognized by scholars and the papers you use should have at least 5 citations.  In particular, when reading the papers, look for relationships among the solution ideas, how the authors evaluated their solutions, and what promising ideas the authors think could improve their work.</p>\n",
    "\n",
    "<p>Use <a href=\"https://ieee-dataport.org/sites/default/files/analysis/27/IEEE%20Citation%20Guidelines.pdf\">IEEE</a> or <a href=\"https://www.acm.org/publications/authors/reference-formatting\">ACM</a> format for listing the paper references.  An example is following.</p>\n",
    "<hr>\n",
    "\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Md. A. Hossain, T. Hasan, F. Ahmed, S. H. Cheragee, M. H. Kanchan, and M. A. Haque, \"Towards superior android ransomware detection: An ensemble machine learning perspective,\" Cyber Security and Applications, vol. 3, p. 100076, 2025. [Online]. Available: https://doi.org/10.1016/j.csa.2024.100076.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Problem:</h5> Ransomware protection for Android devices is inadequate, leaving devices vulernable to attacks. </li>\n",
    "        <li><h5>Past Solution Ideas:</h5>FNN using Keras Sequential, SVM, KNN, Gradient Boosting, AdaBoost.</li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5>XG Boost, Random Forest, CatBoost</li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5>XGBoost's efficiency and scalability makes it well suited for large datasets, as well as supporting regularization to avoid overfitting. </li>\n",
    "        <li><h5>Evaluation Ideas:</h5>Paired t-test and Confusion Matrix, as well as the standard accuracy, precision, recall and F1-Score.</li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5>Implement XGBoost, possibly use a confusion matrix for evaluation.</li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Romero, C. N., Mital, M. E. G., Rostata, Z. D., & Martinez, M. A. M. (2024). Investigating the impact of training and testing ratios on the performance of an AI-based malware detector using MATLAB. E3S Web of Conferences, 50, 001015. https://doi.org/10.1051/e3sconf/202450001015</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Problem:</h5> Different AI models and tasks will respond different to different splits between training and testing data.</li>\n",
    "        <li><h5>Past Solution Ideas: </h5> Many people use a \"standard\" 70/30 training/testing split, or any other split without assessing whether that's the most appropriate one for the task at hand.</li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5>Evaluating your model and determining which kind of training/testing split would be most appropriate.</li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5>Using different training splits to better assess the capabilities of the model being tested.</li>\n",
    "        <li><h5>Evaluation Ideas:</h5>Using different training/testing splits to assess models.</li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5>Test AI models using different training splits like 50/50, 70/30, and 80/20 to see if any of them work better with the model being implemented.</li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>A. Bensaoud, J. Kalita, and M. Bensaoud, \"A Survey of Malware Detection Using Deep Learning,\" Journal of Information and Security Advances, vol. 9, no. 2, pp. 45â€“59, Jul. 2024.</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Problem: </h5>The paper highlights the challenges in detecting malware due to the evolving complexity of malware behavior, and limitations of traditional methods such as signature- and heuristic-based detection, which struggle with novel or polymorphic malware.</li>\n",
    "        <li><h5>Past Solution Ideas: </h5>Examining the binary code without execution (e.g., entropy, API calls), earlier models relied on handcrafted features for malware classification.</li>\n",
    "        <li><h5>Authors' Solution Ideas:</h5>The authors propose using DL techniques, such as CNNs for image-based malware detection and hybrid CNN-RNN models for sequential features. They emphasize the role of pre-trained models and Explainable AI to improve scalability and transparency.</li>\n",
    "        <li><h5>Future Promising Solution Ideas:</h5>Exploring unsupervised learning for detecting unseen malware families and adversarial robustness to evade attacks. The paper also stresses the need for Explainable AI to make malware detection models more transparent.</li>\n",
    "        <li><h5>Evaluation Ideas:</h5>The authors benchmark accuracy, precision, recall, and F1-scores of DL models against traditional methods. They also evaluate the models' resilience to adversarial examples for robustness.</li>\n",
    "        <li><h5>Ideas the Team Would Like to Use From This Paper:</h5>The team will adopt image-based detection with CNNs and explore hybrid CNN-RNN models to improve detection. Investigating adversarial robustness and integrating Explainable AI will also guide model development.</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e750733-0c99-440a-9abc-9fa8da8d722d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2 style=\"color: teal\">From Other Informal Resources</h2>\n",
    "<hr>\n",
    "\n",
    "<p>Informal resources from previous submissions should not be listed here.</p>\n",
    "\n",
    "<p>Other informal resources include work that is not published in journals or conferences, such as blog sites, tutorials, posted software, software package websites, generative AI tools, and past class project reports that are available online.  Such resources may have concrete examples of how to do various solutions and have software packages or resources that can be used in the team's solution.  Such information and resources should be used to enable the team to go further and faster than they could have gone if the team had started from scratch.</p>\n",
    "<hr>\n",
    "<ul>\n",
    "<li style=\"color:maroon\"><h4><bf>GeeksforGeeks, \"ML | Gradient Boosting,\" GeeksforGeeks, Accessed: Nov. 25, 2024, [Online]. Available: https://www.geeksforgeeks.org/ml-gradient-boosting/</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Helpful information/code/ideas/examples:</h5>Using Gradient Boosting to minimize our loss function</li>\n",
    "        <li><h5>What the team would like to use from this resource:</h5>Familiarizing ourselves with the sklearn libraries, as well as how we can effectively implement these techniques with our dataset</li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>TutorialsPoint, \"Scikit-learn - Boosting Methods,\" TutorialsPoint, Accessed: Nov. 25, 2024, [Online]. Available: https://www.tutorialspoint.com/scikit_learn/scikit_learn_boosting_methods.htm</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Helpful information/code/ideas/examples:</h5>Comparing Gradient Boosting vs Ada Boosting, how to use both on datasets</li>\n",
    "        <li><h5>What the team would like to use from this resource:</h5>Further our knowledge and experience with boosting and AI/ML techniques</li>\n",
    "    </ul>\n",
    "<li style=\"color:maroon\"><h4><bf>Y. Young, \"BODMAS: An Open Dataset for Malware Analysis,\" WhyIsYoung Blog, 2021. Available: https://github.com/whyisyoung/BODMAS?tab=readme-ov-file</bf></h4></li>\n",
    "    <ul>\n",
    "        <li><h5>Helpful information/code/ideas/examples:</h5>Includes feature vectors for over 57,000 malware samples and 77,000 benign samples across 581 malware families, and provides curated metadata for static analysis, including byte histograms, entropy, and more.</li>\n",
    "        <li><h5>What the team would like to use from this resource:</h5>Preprocessed feature vectors for training machine learning models, comprehensive labeling of malware families to evaluate classification performance, and feature diversity to enhance model robustness and generalizability.</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa84f4-a1dd-4df8-8fb2-25088b18e92e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color: darkgoldenrod\">Past Plans and Actual Tasks for the Third Project Assignment Submission</h1>\n",
    "\n",
    "<p>The third project assignment submission is the final status report on how far the team has gotten in solving the problem.  Overall, status reports will include but not be limited to items, such as updates to the problem scope, lessons learned, finding more ideas in the conference and journal paper literature as well as informal resources, data sources found, current solution status and performance, comparison of solution to past approaches, software developed and packages used, hardware used, testing, and consideration of new solution approaches.</p>\n",
    "\n",
    "<p>Each team member should catalog the actual work tasks performed for this submission including specfic papers and resources found, AI solution models proposed, preliminary investigative work on a software prototype, researching evaluation strategies for the team's solution, finding needed data files, interviewing experts, solving subproblems, planning, designing, coding, testing, and anything related to helping the team complete the submission well.</p>\n",
    "\n",
    "<p>Tasks should have enough detail to understand clearly and specifically what was done.  For example, rather than say, \"found and wrote up 2 conference papers\", include the authors, such as \"found and wrote up 2 conference papers by Smith et al, 2022, and Breugrand et al, 2019\" so it is clear which papers were contributed to a submission.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Each team member plans to apply an AI solution to the problem and has the following accomplishments and plans:\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"color: maroon\"><bf>Team Member Name</bf></th>\n",
    "        <th style=\"color: maroon\"><bf>Planned Team Member Tasks for Third Submission</bf></th>\n",
    "        <th style=\"color: maroon\"><bf>Actual Team Member Tasks for Third Submission</bf></th>\n",
    "    </tr>\n",
    "    <tr style=\"text-align:left\">\n",
    "        <th>Harper Hill</th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Refine final models ~5-6 hours</li>\n",
    "                <li>Establish testing methodology, ~2-3 hours</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Tasks planned from the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Optimize Decision Tree. -4 hours</li>\n",
    "                <li>Implement and test KNN. -10 hours</li>\n",
    "                <li>Test performance and compare to performance of existing models. -5 hours</li>\n",
    "                <li>Fill out report. -3 hours</li>\n",
    "            </ul>\n",
    "            </ul>\n",
    "        </th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks actually done for the third submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Optimize Decision Tree. -5 hours</li>\n",
    "                <li>Test performance and compare to performance of existing models. -4 hours</li>\n",
    "                <li>Fill out report. -3 hours</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            </ul>\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr style=\"text-align:left\">\n",
    "        <th>Kharis Asifor-Paul</th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Investigate AI-based malware detection techniques and gather relevant datasets (malicious vs. benign software), ~5hrs</li>\n",
    "                <li>Design AI models, like decision trees or neural networks, that classify software based on the patterns in the collected data, ~4-5hrs</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Tasks planned from the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Complete model training; achieve preliminary results of at least 85% accuracy, ~5-6hrs</li>\n",
    "                <li>Documented issues with dataset imbalance and strategies to address this through resampling, ~2-3hrs</li>\n",
    "                <li>Finalize findings and conclude report, ~2hrs</li>\n",
    "            </ul>\n",
    "            </ul>\n",
    "        </th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks actually done for the third submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Integrated the BODMAS dataset into the workflow and applied normalization techniques using MinMaxScaler to prepare features for the CNN model, ~5-6hrs</li>\n",
    "                <li>Designed and trained a Convolutional Neural Network (CNN) for malware classification and achieved a test accuracy of 93%, validating the effectiveness of the feature selection and preprocessing, ~7-8hrs</li>\n",
    "                <li>Conducted performance evaluation and comparison and benchmarked the CNN model against similar models from the informal resource, ~5hrs</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            </ul>\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr style=\"text-align:left\">\n",
    "        <th>Zack Sims</th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks planned from the proposal submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Implement AI search and other useful AI techniques into problem, ~4-5 hours</li>\n",
    "                <li>Develop code base and develop agent, ~4-5 hours</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li><bf>Tasks planned from the second submission</bf></li>\n",
    "            <ul>\n",
    "                <li>Implement the agent in software, 10+ hours</li>\n",
    "                <li>Choose a dataset to train our agent on, 1-2 hours of deliberation</li>\n",
    "                <li>Continue work in developing algorithms and software to aid our agent in making optimal choices, 10-12 hours</li>\n",
    "                <li>Perform performance benchmarking and compare these results with other implemenations, 6 hours</li>\n",
    "            </ul>\n",
    "            </ul>\n",
    "        </th>\n",
    "        <th><ul>\n",
    "            <li><bf>Tasks actually done for the third submission</bf></li>\n",
    "            <ul>\n",
    "                <li>task, actual time or time estimate</li>\n",
    "                <li>task, actual time or time estimate</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            </ul>\n",
    "        </th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f71f4-6357-4057-8c39-5d8a6d7b800c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"color: darkgoldenrod\">Current Solution Status</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffa796-2ef5-46fd-bdf7-1d7774298edb",
   "metadata": {},
   "source": [
    "<h2 style=\"color:teal\">What computer hardware, programming language, main software packages, and data files are recommended to be used to run the software for this submission?</h2>\n",
    "    <ul>\n",
    "        <li><h5 style=\"color:maroon\">Computer Hardware</h5>Minimum: Any modern, multi-core CPU, 4GB RAM minimum. Reccomended: 8 core CPU, 8-16 GB memory. </li>\n",
    "        <li><h5 style=\"color:maroon\">Programming Language</h5>Python 3.12.2</li>\n",
    "        <li><h5 style=\"color:maroon\">Main Software Packages</h5>scikit-learn, pandas, numpy, matplotlib</li>\n",
    "        <li><h5 style=\"color:maroon\">Data</h5>Malware database for training from: \n",
    "            <li>https://www.kaggle.com/datasets/subhajournal/android-malware-detection\n",
    "    <li> https://github.com/whyisyoung/BODMAS?tab=readme-ov-file</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4681706-eda0-4131-9418-1c803a494611",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2 style=\"color: teal\">What is the performance of the team's solutions in comparison with results from journal/conference papers and other informal resources since the last submission?</h2>\n",
    "\n",
    "<p>Comparisons from previous submissions should not be listed here.</p>\n",
    "\n",
    "<p>For the third submission, each team member should plan to add at least one more reference for comparison of performance regardless of how many are given in submission two.  Performance includes but is not limited to the amount of memory consumed, the order of the algorithms used, computation time, number of operations performed, experimental results on various data sets or trials, and measurements, such as precision, recall, accuracy, F-measure, and cluster purity/silouette.  Graphs, such as the ROC curve, precision/recall curve, scatter plots showing the relationship between two attributes, line charts showing model performance at various training points, and bar charts comparing approaches, may also be used.</p>\n",
    "\n",
    "<p>If a direct comparison is not available, try to find a reference that is similar in nature.  In addition, discuss with the course instructors any difficulty you are having in finding references to compare against.  Other ideas include implementing more solutions to compare against each other.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Harper Hill - Cleaning Dataset, Narrowing to Most Important Attributes, and Expirementing With Different Training/Testing Splits</h3>\n",
    "\n",
    "<p>For this sprint I focused on testing the effects of manipulating the dataset and the training/testing split on the accuracy of the Decision Tree model.  I wanted to see how much of an effect there was on the model after I removed unnecessary columns from the dataset, after I selected k best features, and changed the percentage of data used for testing and training.</p>\n",
    "\n",
    "<h4 style=\"color:darkblue\">Paper/Informal Reference:</h4>\n",
    "<p>Romero, C. N., Mital, M. E. G., Rostata, Z. D., & Martinez, M. A. M. (2024). Investigating the impact of training and testing ratios on the performance of an AI-based malware detector using MATLAB. E3S Web of Conferences, 50, 001015. https://doi.org/10.1051/e3sconf/202450001015</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"color: darkgreen\"><bf>Comparison with Reference Solution</bf></th>\n",
    "        <th style=\"color: darkgreen\"><bf>Reasons why the performance of the team's solution is better/same/worse</bf></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>The reference solution demonstrated an accuracy of 52.20% with a 50/50 training/testing split, and a 49.33% accuracy with a 70/30 split.  Our implementation had a 50.01% accuracy with a 50/50 split and a 50.03% accuracy with a 70/30 split.  Our accuracy peaked at a 50.05% with a 68/32 training split.</th>\n",
    "        <th>When testing our model I found that removing unnecessary data from the dataset didn't affect the outcome of the model, and that selecting k best features only lowered the accuracy of the model below k=45, and didn't change it above that.  I think this shows that decision trees are fairly robust since ours wasn't being tricked by the unimportant data it was given, and it can make use of a wide range of factors to help it make it's decisions.  The accuracy peaking at a 68/32 split I thought was interesting since it dropped off on either side of that.  This could possibly be due to how the data is distributed in the table and the difference is very small, but it's good to know that this is something that can affect the evaluation of our model.</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "...\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Kharis Asifor-Paul - Integration of Advanced Static Analysis Features</h3>\n",
    "\n",
    "<p>The team's solution utilizes a Convolutional Neural Network (CNN) trained on static analysis features derived from the BODMAS dataset. These features include byte histograms and entropy values, which are normalized and fed into the CNN for binary classification of malware and benign files. The model achieved a validation accuracy, demonstrating its capability to detect malware effectively. Future iterations aim to incorporate Explainable AI concepts and hybrid CNN-RNN architectures to improve interpretability and robustness.</p>\n",
    "\n",
    "<h4 style=\"color:darkblue\">Paper/Informal Reference:</h4>\n",
    "<p>Y. Young, \"BODMAS: An Open Dataset for Malware Analysis,\" WhyIsYoung Blog, 2021. Available: https://github.com/whyisyoung/BODMAS?tab=readme-ov-file</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"color: darkgreen\"><bf>Comparison with Reference Solution</bf></th>\n",
    "        <th style=\"color: darkgreen\"><bf>Reasons why the performance of the team's solution is better/same/worse</bf></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>The CNN model achieved a Test Accuracy of 93% when trained on the BODMAS feature vectors.</th>\n",
    "        <th>The CNN model outperformed traditional machine learning models (e.g., Decision Trees, which achieved ~85% accuracy on the same dataset). Feature normalization and early stopping techniques were crucial for preventing overfitting.</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "...\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Zack Sims - Fill in Descriptive Name</h3>\n",
    "\n",
    "<p>Fill in description of team solution</p>\n",
    "\n",
    "<h4 style=\"color:darkblue\">Paper/Informal Reference:</h4>\n",
    "<p>Fill in reference journal</p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"color: darkgreen\"><bf>Comparison with Reference Solution</bf></th>\n",
    "        <th style=\"color: darkgreen\"><bf>Reasons why the performance of the team's solution is better/same/worse</bf></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Fill in reference description solution and performance, and comparison between team's solution and the reference's solution</th>\n",
    "        <th>Fill in reasons for the performance differences or lack of differences between the reference and team solutions</th>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "...\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:maroon\">Discussion/Summary of Solution Results</h3>\n",
    "\n",
    "<p>Please use this section to use items, such as well-labeled graphs and tables, to show a comparison of all team member solutions against each other and with the paper/informal reference solutions, to show a summary of all solution results, and give a discussion of what could be planned to be done for a hypothetical next submission to continue to improve the performance of each team member's solution.</p>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e79bd9-e8dc-4769-b9ab-d709b16918a6",
   "metadata": {},
   "source": [
    "\n",
    "<h1 style=\"color: darkgoldenrod\">Software</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beed320-23a0-4664-9483-b0e626619d81",
   "metadata": {},
   "source": [
    "<p>Please be sure to submit a requirements.txt file so that the instructors can easily run the code in this Jupyter Notebook.  The requirements.txt file should be in the same working directory as the Jupyter Notebook.  Also, please give any special instructions beyond the normal running of code in a Jupyter Notebook, such as where data files should be placed if not in the working directory of this Jupyter Notebook or if some of the installed software packages have additional requirements beyond \"pip install\".</p>\n",
    "\n",
    "<p>Each code cell should have contextually related code, such as a class, function implementing a major algorithm, or a set of short functions that support a larger function in a subsequent cell.  Code cells should also be present to show the performance/evaluation of a solution through well labeled graphs, tables, and/or performance measure values.</p>\n",
    "\n",
    "<p>The code cells also can be organized by each team member's solution.</p>\n",
    "\n",
    "<p>Each major set of related code cells should have the purpose of the code cells, the paper/informal references used (if any) to develop the code in the code cells, the team members who worked on the code cells, and major changes made to the code in the code cells by team members for this submission.  Changes made in a previous submission should not be included.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2 style=\"color: teal\">Are there any special instructions for running the code in this Jupyter Notebook for this submission?</h2>\n",
    "\n",
    "<ul>\n",
    "    <li>Download 'bodmas_metadata.csv' dataset from GitHub repo, available at https://github.com/whyisyoung/BODMAS?tab=readme-ov-file</li>\n",
    "    <li>To get the dataset for the Decision Tree solution, download Android_Malware.csv from this link https://www.kaggle.com/datasets/subhajournal/android-malware-detection</li>\n",
    "</ul>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88e6faba-e744-4216-a5a7-55834d8773b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#to capture all of the installed packages so far (run by the team to submit with the Jupyter notebook)\n",
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e9b9ece-5297-4cb8-a663-7587f16459d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages to import to run the code in the Jupyter Notebook\n",
    "#For Decision Tree implementation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f851b0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Code Cell Block - Data Preparation for Decision Tree</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>The below code imports the dataset, removes unecessary columns, and displays some information about it for the user.</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://www.kaggle.com/code/mahmoudasla/android-malware-detection-0c4368</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Harper Hill</h5>\n",
    "<li>This code block is reused from the second submission for convenience and consistency</li>\n",
    "<ul>\n",
    "    <li>11/03/2024 - Added dataset and some cleaning of data</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3c217b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-a6939d9a5e56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dataset/Android_Malware.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('Dataset/Android_Malware.csv', low_memory=False)\n",
    "df.shape\n",
    "df.head()\n",
    "df.columns\n",
    "\n",
    "df.drop(['Unnamed: 0','Flow ID',' Timestamp',' CWE Flag Count',' Down/Up Ratio','Fwd Avg Bytes/Bulk'], axis=1, inplace=True)\n",
    "le = LabelEncoder()\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        df[i] = le.fit_transform(df[i])\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.isnull().sum().sort_values(ascending=False).head()\n",
    "df.dropna(axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565039db-a366-44bf-adf9-f5928380d74a",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Comparing Boosted Decision Trees no Non-Boosted Trees</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose:</h4>\n",
    "\n",
    "<p>See what impact boosting will have on our current decison tree</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>GeeksforGeeks, \"ML | Gradient Boosting,\" GeeksforGeeks, Accessed: Nov. 25, 2024, [Online]. Available: https://www.geeksforgeeks.org/ml-gradient-boosting/</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Zack Sims</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>11/23/2024: Wrote software and compared results</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246c995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      "[2. 2. 0. ... 0. 0. 2.]\n",
      "Confusion Matrix:  [[33061   207 11042     0]\n",
      " [ 8988  5160  4997     0]\n",
      " [19163  1194 14528     0]\n",
      " [ 4344    57  2703     0]]\n",
      "Accuracy :  50.02560600887676\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.75      0.60     44310\n",
      "         1.0       0.78      0.27      0.40     19145\n",
      "         2.0       0.44      0.42      0.43     34885\n",
      "         3.0       0.00      0.00      0.00      7104\n",
      "\n",
      "    accuracy                           0.50    105444\n",
      "   macro avg       0.43      0.36      0.36    105444\n",
      "weighted avg       0.50      0.50      0.47    105444\n",
      "\n",
      "Predicted values:\n",
      "[2. 2. 0. ... 0. 0. 2.]\n",
      "Confusion Matrix:  [[33061   207 11042     0]\n",
      " [ 8988  5160  4997     0]\n",
      " [19163  1194 14528     0]\n",
      " [ 4344    57  2703     0]]\n",
      "Accuracy :  50.02560600887676\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.75      0.60     44310\n",
      "         1.0       0.78      0.27      0.40     19145\n",
      "         2.0       0.44      0.42      0.43     34885\n",
      "         3.0       0.00      0.00      0.00      7104\n",
      "\n",
      "    accuracy                           0.50    105444\n",
      "   macro avg       0.43      0.36      0.36    105444\n",
      "weighted avg       0.50      0.50      0.47    105444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Zack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Zack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Zack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Zack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Zack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#this is our non boosted decision tree implementation from the previous stage, not unique to this submission\n",
    "X = df.values[:, 0:78]\n",
    "Y = df.values[:, 79]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.3, random_state=100)\n",
    "\n",
    "#entropy clf\n",
    "clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", random_state=100, max_depth=3, min_samples_leaf=5)\n",
    "clf_entropy.fit(x_train, y_train)\n",
    "\n",
    "#gini clf\n",
    "clf_gini = DecisionTreeClassifier(criterion=\"gini\",random_state=100,max_depth=3,min_samples_leaf=5)\n",
    "clf_gini.fit(x_train, y_train)\n",
    "\n",
    "#Make prediction for entropy tree\n",
    "entropy_y_pred = clf_entropy.predict(x_test)\n",
    "print(\"Predicted values:\")\n",
    "print(entropy_y_pred)\n",
    "\n",
    "#Print confusion matrix and accuracy for entropy tree\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, entropy_y_pred))\n",
    "print(\"Accuracy : \", accuracy_score(y_test, entropy_y_pred)*100)\n",
    "print(\"Report : \", classification_report(y_test, entropy_y_pred))\n",
    "\n",
    "#commented out graphics for screen space and conveinience\n",
    "#plt.figure(figsize=(15,10))\n",
    "#plot_tree(clf_entropy, feature_names=df.columns, class_names=['Android_Adware', 'Android_Scareware', 'Android_SMS_Malware', 'Benign'], filled=True, rounded=True)\n",
    "#plt.show()\n",
    "\n",
    "#Make prediction for gini tree\n",
    "gini_y_pred = clf_gini.predict(x_test)\n",
    "print(\"Predicted values:\")\n",
    "print(gini_y_pred)\n",
    "\n",
    "#Print confusion matrix and accuracy for gini tree\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, gini_y_pred))\n",
    "print(\"Accuracy : \", accuracy_score(y_test, gini_y_pred)*100)\n",
    "print(\"Report : \", classification_report(y_test, gini_y_pred))\n",
    "\n",
    "#plt.figure(figsize=(15,10))\n",
    "#plot_tree(clf_gini, feature_names=df.columns, class_names=['Android_Adware', 'Android_Scareware', 'Android_SMS_Malware', 'Benign'], filled=True, rounded=True)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60f3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      " [1.20858525 1.29126211 1.03523184 ... 1.00345389 0.99009336 1.05952189]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, gb_prediction)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#print actual values\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgb_prediction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy : \u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, gb_prediction)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReport : \u001b[39m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test, gb_prediction))\n",
      "File \u001b[1;32mc:\\Users\\Zack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Zack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    248\u001b[0m     {\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m    (np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\Zack\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:112\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    109\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    114\u001b[0m             type_true, type_pred\n\u001b[0;32m    115\u001b[0m         )\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    119\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "#this will be the gradient boosting implementation\n",
    "X = df.values[:, 0:78]\n",
    "Y = df.values[:, 79]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = .3, random_state=100)\n",
    "\n",
    "#classify and fit to the training set\n",
    "gb_clf = GradientBoostingClassifier(n_estimators = 100, learning_rate = .05, random_state = 100, max_features = 5)\n",
    "gb_clf.fit(x_train, y_train)\n",
    "\n",
    "gb_prediction = gb_clf.predict(x_test)\n",
    "print(\"Predicted values:\\n\", gb_prediction)\n",
    "\n",
    "#print actual values\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, gb_prediction))\n",
    "print(\"Accuracy : \", accuracy_score(y_test, gb_prediction)*100)\n",
    "print(\"Report : \", classification_report(y_test, gb_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ab8c0",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Comparing Decision Trees to Decision Trees With Refined Datasets</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose:</h4>\n",
    "\n",
    "<p>See what impact removing unnecessary data will have on the accuracy of the decision tree.  Also testing what effect changing the testing/training split will have on the accuracy of the model.</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>Athira, D. Baburaj and D. Gupta, \"A Comprehensive Exploration of Machine Learning and Explainable AI Techniques for Malware Classification,\" 2024 2nd World Conference on Communication & Computing (WCONF), RAIPUR, India, 2024, pp. 1-7, doi: 10.1109/WCONF61366.2024.10692299. keywords: {Measurement;Deep learning;Recurrent neural networks;Explainable AI;Forestry;Boosting;Malware;Convolutional neural networks;Computer crime;Random forests;Malware;Machine Learning;KNN;Random Forest;Decision Tree;XGBoost;AdaBoost},</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Harper Hill</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>11/24/2024: Added Variance Threshold and SelectKBest to optimize data being fed to decision tree.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9592df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy Tree\n",
      "Predicted values:\n",
      "[2. 2. 0. ... 0. 0. 0.]\n",
      "Confusion Matrix:  [[35265   222 11752     0]\n",
      " [ 9571  5485  5350     0]\n",
      " [20442  1270 15544     0]\n",
      " [ 4633    59  2881     0]]\n",
      "Accuracy :  50.050678379003145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harpe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\harpe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\harpe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.75      0.60     47239\n",
      "         1.0       0.78      0.27      0.40     20406\n",
      "         2.0       0.44      0.42      0.43     37256\n",
      "         3.0       0.00      0.00      0.00      7573\n",
      "\n",
      "    accuracy                           0.50    112474\n",
      "   macro avg       0.43      0.36      0.36    112474\n",
      "weighted avg       0.50      0.50      0.47    112474\n",
      "\n",
      "Gini tree\n",
      "Predicted values:\n",
      "[2. 2. 0. ... 0. 0. 0.]\n",
      "Confusion Matrix:  [[35265   222 11752     0]\n",
      " [ 9571  5485  5350     0]\n",
      " [20442  1270 15544     0]\n",
      " [ 4633    59  2881     0]]\n",
      "Accuracy :  50.050678379003145\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.75      0.60     47239\n",
      "         1.0       0.78      0.27      0.40     20406\n",
      "         2.0       0.44      0.42      0.43     37256\n",
      "         3.0       0.00      0.00      0.00      7573\n",
      "\n",
      "    accuracy                           0.50    112474\n",
      "   macro avg       0.43      0.36      0.36    112474\n",
      "weighted avg       0.50      0.50      0.47    112474\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harpe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\harpe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\harpe\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#this is our non boosted decision tree implementation from the previous stage\n",
    "#with the addition of removing features that have no variance\n",
    "#and selecting k best features\n",
    "#as well as changing the training/testing split\n",
    "\n",
    "X_old = df.values[:, 0:78]\n",
    "Y = df.values[:, 79]\n",
    "\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "X_no_variance = vt.fit_transform(X_old)\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=45)\n",
    "X = selector.fit_transform(X_no_variance,Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.32, random_state=100)\n",
    "\n",
    "#entropy clf\n",
    "clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", random_state=100, max_depth=3, min_samples_leaf=5)\n",
    "clf_entropy.fit(x_train, y_train)\n",
    "\n",
    "#gini clf\n",
    "clf_gini = DecisionTreeClassifier(criterion=\"gini\",random_state=100,max_depth=3,min_samples_leaf=5)\n",
    "clf_gini.fit(x_train, y_train)\n",
    "\n",
    "#Make prediction for entropy tree\n",
    "entropy_y_pred = clf_entropy.predict(x_test)\n",
    "print(\"Entropy Tree\")\n",
    "print(\"Predicted values:\")\n",
    "print(entropy_y_pred)\n",
    "\n",
    "#Print confusion matrix and accuracy for entropy tree\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, entropy_y_pred))\n",
    "print(\"Accuracy : \", accuracy_score(y_test, entropy_y_pred)*100)\n",
    "print(\"Report : \", classification_report(y_test, entropy_y_pred))\n",
    "\n",
    "#commented out graphics for screen space and conveinience\n",
    "#plt.figure(figsize=(15,10))\n",
    "#plot_tree(clf_entropy, feature_names=df.columns, class_names=['Android_Adware', 'Android_Scareware', 'Android_SMS_Malware', 'Benign'], filled=True, rounded=True)\n",
    "#plt.show()\n",
    "\n",
    "#Make prediction for gini tree\n",
    "gini_y_pred = clf_gini.predict(x_test)\n",
    "print(\"Gini tree\")\n",
    "print(\"Predicted values:\")\n",
    "print(gini_y_pred)\n",
    "\n",
    "#Print confusion matrix and accuracy for gini tree\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, gini_y_pred))\n",
    "print(\"Accuracy : \", accuracy_score(y_test, gini_y_pred)*100)\n",
    "print(\"Report : \", classification_report(y_test, gini_y_pred))\n",
    "\n",
    "#plt.figure(figsize=(15,10))\n",
    "#plot_tree(clf_gini, feature_names=df.columns, class_names=['Android_Adware', 'Android_Scareware', 'Android_SMS_Malware', 'Benign'], filled=True, rounded=True)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44024dbf-a49d-4901-8d34-cab79c43429c",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon\">Integration of BODMAS Dataset with CNN for Malware Classification</h3>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Purpose</h4>\n",
    "\n",
    "<p>Train a Convolutional Neural Network (CNN) for binary classification of malware and benign files. This demonstrates the integration of advanced static analysis features into a deep learning model for malware detection.</p>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">References used to develop the code</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>https://github.com/whyisyoung/BODMAS?tab=readme-ov-file.</li>\n",
    "</ul>\n",
    "\n",
    "<h4 style=\"color:darkgreen\">Team members contributing to the code cell block</h4>\n",
    "\n",
    "<h5 style=\"color:darkblue\">Kharis Asifor-Paul</h5>\n",
    "\n",
    "<ul>\n",
    "    <li>11/23/2024 - Integrated the BODMAS dataset into the project, trained a CNN model, and benchmarked results.\n",
    "</li>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BODMAS feature vectors\n",
    "filename = 'bodmas_metadata.csv'\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "# Explore the dataset structure\n",
    "print(data.info())\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop('label', axis=1)  # Drop the label column to get features\n",
    "y = data['label']  # Binary labels: 0 = benign, 1 = malware\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training vs. Validation Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
